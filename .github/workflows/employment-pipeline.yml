name: Employment Pipeline

# ── Schedule: aligned to PLFS release cycles ────────────────────────
# PLFS Quarterly Bulletin released ~2 months after quarter end.
# PLFS Annual Report released mid-year.
# World Bank labour indicators update mid-year.
#
# Quarterly runs catch World Bank updates and PLFS releases.
# Curated data (PLFS state data, sectoral KLEMS) lives in pipeline
# source files and must be updated manually when new reports publish.

on:
  schedule:
    # Quarterly: 1st of Mar, Jun, Sep, Dec — 6 AM UTC (11:30 AM IST)
    - cron: '0 6 1 3 *'     # Mar 1 — catch Oct-Dec PLFS bulletin
    - cron: '0 6 1 6 *'     # Jun 1 — catch Jan-Mar PLFS bulletin
    - cron: '0 6 1 9 *'     # Sep 1 — catch Apr-Jun PLFS + annual report
    - cron: '0 6 1 12 *'    # Dec 1 — catch Jul-Sep PLFS bulletin
  workflow_dispatch:
    inputs:
      force_refresh:
        description: 'Force re-download and re-process all data'
        type: boolean
        default: false

permissions:
  contents: write
  issues: write

jobs:
  update-employment-data:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install pipeline dependencies
        run: |
          cd pipeline
          pip install requests pydantic

      - name: Run Employment pipeline
        run: |
          cd pipeline
          python src/employment/main.py

      - name: Check for data changes
        id: changes
        run: |
          git diff --quiet public/data/employment/ && echo "changed=false" >> $GITHUB_OUTPUT || echo "changed=true" >> $GITHUB_OUTPUT

      - name: Commit updated data
        if: steps.changes.outputs.changed == 'true'
        run: |
          git config user.name "India Data Pipeline"
          git config user.email "pipeline@india-data-portal.dev"
          git add public/data/employment/
          git commit -m "data: update Employment data $(date +%Y-%m-%d)

          Automated pipeline run. Sources: World Bank API + curated PLFS/KLEMS data.
          Triggered by: ${{ github.event_name }}"
          git push

      - name: Open issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Employment pipeline failure: ${new Date().toISOString().slice(0,10)}`,
              body: `The Employment data pipeline failed.\n\n` +
                    `**Trigger:** ${context.eventName}\n` +
                    `**Run:** ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}\n\n` +
                    `The frontend continues serving the last known good data.`,
              labels: ['pipeline', 'automated']
            });
